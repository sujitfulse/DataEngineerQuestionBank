-----------------------------------------------------------------------------------------------------------------------------------------------------------------
38	in HIVE, Explain the Difference between cluster by & distribute by with example ..??
      *DISTRIBUTE BY clause is used to distribute the input rows among reducers. 
      - It ensures that all rows for the same key columns are going to the same reducer. 
      - So, if we need to partition the data on some key column, we can use the DISTRIBUTE BY clause in the hive queries. 
      - However, the DISTRIBUTE BY clause does not sort the data either at the reducer level or globally. 
      - Also, the same key values might not be placed next to each other in the output dataset.

set mapreduce.job.reduces=2;
select * from transactions distribute by acct; // not sorted data  
select * from hivesql.transactions CLUSTER BY acct; // sorted at reducer level. its shortcut to distribute by acct sort by acct.


	* CLUSTER BY
	- CLUSTER BY clause is a combination of DISTRIBUTE BY and SORT BY clauses together.
	- That means the output of the CLUSTER BY clause is equivalent to the output of DISTRIBUTE BY + SORT BY clauses. 
	- The CLUSTER BY clause distributes the data based on the key column and then sorts the output data by putting the same key column values adjacent 
	to each other. So, the output of the CLUSTER BY clause is sorted at the reducer level. 
	- As a result, we can get N number of sorted output files where N is the number of reducers used in the query processing. 
	- Also, the CLUSTER by clause ensures that we are getting non-overlapping data ranges into the final outputs.
	- However, if the query is processed by only one reducer the output will be equivalent to the output of the ORDER BY clause.

https://sqlrelease.com/sort-by-order-by-distribute-by-and-cluster-by-in-hive

------------------------------------------------------------------------------------------------------------------------------------------------------- 

31	what are Serde properties
	- SerDe is short for Serializer/Deserializer. 
	- Hive uses the SerDe interface for IO. 
	- The interface handles both serialization and deserialization and also interpreting the results of serialization as individual fields for processing.
	- Built-in SerDes
		Avro (Hive 0.9.1 and later)
		ORC (Hive 0.11 and later)
		RegEx
		Thrift
		Parquet (Hive 0.13 and later)
		CSV (Hive 0.14 and later)
		JsonSerDe (Hive 0.12 and later in hcatalog-core)
		
		
Hive context in spark
	Hive comes bundled with the Spark library as HiveContext, which inherits from SQLContext. 
	Using HiveContext, you can create and find tables in the HiveMetaStore and write queries on it using HiveQL. 
	Users who do not have an existing Hive deployment can still create a HiveContext.
  
  val cc = new SparkConf;
  val sc = new SparkContext(cc)
  val sparkSession = SparkSession.builder().enableHiveSupport().getOrCreate()
  //First option for creating hive table through dataframe 
  val DF = sparkSession.sql("select * from salary")
  DF.createOrReplaceTempView("tempTable")
  sparkSession.sql("Create table yourtable as select * form tempTable")
  
------------------------------------------------------------------------------------------------------------------------------------------------------- 
 157	HIVE : what if partition is deleted from external table and will it give error while a select ?

    - To delete data in external table you need to delete files on the filesystem. Data in the external table will remain if you drop table or partition. 
------------------------------------------------------------------------------------------------------------------------------------------------------- 
  
158  MSCK REPAIR TABLE command
    -  MSCK REPAIR TABLE command. This will restore all the partitions that are not in the metastore but exist on the file system, 
    So, with an external table, if you want the data in a partition to be gone when you drop it, 
    you have to also go and delete it from the filesystem. Otherwise, the data will continue to exist and 
    there is a good chance that someone will bring the metadata for it back into the metastore.
    
   * convert external table into managed one- 
    ALTER TABLE abc SET TBLPROPERTIES('EXTERNAL'='FALSE');
    
   * DELETE DEFAULT PARTITIONS FROM HIVE.
    ALTER TABLE Table_Name DROP IF EXISTS PARTITION(process_date='__HIVE_DEFAULT_PARTITION__')

------------------------------------------------------------------------------------------------------------------------------------------------------- 

159	how to improve performance of two big tables in hive ?
  optimize.bucketmapjoin=true;
-------------------------------------------------------------------------------------------------------------------------------------------------------  
  164	List hive  analytic functions you used in project 
==> lead , lag, Rownumber
------------------------------------------------------------------------------------------------------------------------------------------------------- 

110	"What is Hive on Spark?
  Hive contains significant support for Apache Spark, wherein Hive execution is configured to Spark:

  hive> set spark.home=/location/to/sparkHome;
  hive> set hive.execution.engine=spark;"
1	DDL functions of hive
2	Partition & Bucketing
3	Why manage table ?
4	Types of hive tables and where u used this table in ur project.

11	What is your Default partition using in your project
12	Is it Possible to Delete and Update in Hive Table. Have You used in Your Project
14	How you will insert values to the hive table from one table using case condition
15	Syntax of map side join and why we go for map side join
16	What is the max size of map side join small table
18	What is hive metastore , where it is saved in prod cluster?
22	write a hive query to join 3 tables, Where the second largest table should go to memory With optimization
23	External table create
24	Load data to external table
25	does hive support OLTP operations?
26	how does hive work internally?
27	hive supports only OLAP then how can it support insert commands
28	does hive also work on Write Once Read Many?
29	bucketing, static and dynamic partitioning in hive
30	how to use explode in hive
31	about trim function in hive
32	hive performance tuning
34	what different kind of tables we can create in hive
35	Hive and spark optimizations
36	can we define foreign and primary key in hive tables
37	how can we do the data quality check in spark and hive
38	What is vectorization and how does it improves performance?
39	Can we use analytic functions on RDD? (i don't exactly know what he meant)
40	"skew join : 
https://medium.com/expedia-group-tech/skew-join-optimization-in-hive-b66a1f4cc6ba
"
41	"hive optimization : 
https://acadgild.com/blog/hive-optimization-techniques-with-examples

"
42	hive indexing : https://acadgild.com/blog/indexing-in-hive
43	Explain the Difference between group by, order by, cluster by & distribute by with example ..??
44	What if you have deleted the data of manage table created  on top of HDFS location ??  Will the data be available or not??
45	Why bucketing is preferred even though the nested partition can optimize the problemâ€¦
46	https://analyticshut.com/hive-collect-set-vs-collect-list/
47	Optimization techniques in hive and optimization techniques you have implemented in project ??
48	On which column you did partition in hive in your project ??
49	Lets say you have created partition for Hyderabad but you loaded Chennai data , what are the validation we have to done in this case to make sure that there won't be any errors
50	gave a hive table and asked to write output for inner,outer joins 
51	query to find out number of duplicate records in hive table 
52	how to update records in hive 
53	difference between cluster by and distributed by in hive
54	Hive table partition deleted
55	Suppose we put string values in int table, what's the result?
56	Broadcast join
57	Map Side Join
58	SMB joins
59	Large datasets join 
60	If we delete partition in hive, after querying the same, is it visible?
61	ORC vs Parquet
62	From which hive version ACID implemented in hive
63	how can we retrieve deleted metadata of external table.
64	9. Hive :  Scenario: Imagine we have 2 tables A and B.
65	B is the master table and A is the table which receives the updates of certain information
66	so i want to update table B using the latest updated columns based up on the id how do we achieve that and what is the exact query we use?
67	10.What is use of Row-index and in which scenarios have you used it in hive?
68	11. what is Ntile?
69	laterl view explode in hive
70	broadcast in hive and broadcast in spark
